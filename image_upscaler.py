"""
ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ëª¨ë“ˆ
Real-ESRGAN, SwinIR, Stable Diffusion x4 Upscalerë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§
ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬ì™€ ìŠ¤ë§ˆíŠ¸í•œ í¬ê¸° ê´€ë¦¬ í¬í•¨
"""

import os
import numpy as np
import torch
import cv2
from PIL import Image, ImageFilter
import streamlit as st
from io import BytesIO
import tempfile
import requests
import gc
import psutil
from typing import Optional, Tuple

class ImageUpscaler:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.models = {}
        self.memory_threshold_mb = 8192  # 8GB RAM threshold
        
    def get_memory_info(self) -> dict:
        """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´ ë°˜í™˜"""
        memory = psutil.virtual_memory()
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            gpu_used = torch.cuda.memory_allocated(0) / 1024**3
        else:
            gpu_memory = 0
            gpu_used = 0
            
        return {
            'total_ram_gb': memory.total / 1024**3,
            'available_ram_gb': memory.available / 1024**3,
            'used_ram_percent': memory.percent,
            'gpu_memory_gb': gpu_memory,
            'gpu_used_gb': gpu_used
        }
    
    def can_handle_large_image(self, image_size: Tuple[int, int]) -> bool:
        """ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¥¸ ì²˜ë¦¬ ê°€ëŠ¥ì„± í™•ì¸"""
        width, height = image_size
        pixel_count = width * height
        memory_info = self.get_memory_info()
        
        # ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ì¶”ì • (ì±„ë„ ìˆ˜ ê³ ë ¤)
        estimated_memory_mb = (pixel_count * 3 * 4 * 16) / 1024**2  # 16x safety factor
        
        available_memory_mb = memory_info['available_ram_gb'] * 1024
        
        return estimated_memory_mb < available_memory_mb * 0.5  # 50% ì•ˆì „ ë§ˆì§„
    
    def get_optimal_tile_size(self, image_size: Tuple[int, int]) -> Tuple[int, int]:
        """ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ìµœì  íƒ€ì¼ í¬ê¸° ê³„ì‚°"""
        memory_info = self.get_memory_info()
        available_gb = memory_info['available_ram_gb']
        
        if available_gb > 16:
            return (1024, 1024)
        elif available_gb > 8:
            return (512, 512)
        else:
            return (256, 256)
    
    def tile_based_processing(self, image: Image.Image, process_func, tile_size: Optional[Tuple[int, int]] = None, overlap: int = 32) -> Image.Image:
        """íƒ€ì¼ ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ"""
        if tile_size is None:
            tile_size = self.get_optimal_tile_size(image.size)
        
        tile_w, tile_h = tile_size
        width, height = image.size
        
        # íƒ€ì¼ì´ í•„ìš” ì—†ëŠ” ê²½ìš°
        if width <= tile_w and height <= tile_h:
            return process_func(image)
        
        st.info(f"í° ì´ë¯¸ì§€ë¥¼ {tile_w}x{tile_h} íƒ€ì¼ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì´ˆê¸°í™”
        result_width = width * 4  # 4x upscale ê°€ì •
        result_height = height * 4
        result = Image.new('RGB', (result_width, result_height))
        
        # íƒ€ì¼ë³„ ì²˜ë¦¬
        for y in range(0, height, tile_h - overlap):
            for x in range(0, width, tile_w - overlap):
                # íƒ€ì¼ ì˜ì—­ ê³„ì‚°
                x_end = min(x + tile_w, width)
                y_end = min(y + tile_h, height)
                
                # íƒ€ì¼ ì¶”ì¶œ
                tile = image.crop((x, y, x_end, y_end))
                
                # íƒ€ì¼ ì²˜ë¦¬
                processed_tile = process_func(tile)
                
                if processed_tile:
                    # ê²°ê³¼ì— íƒ€ì¼ ë¶™ì—¬ë„£ê¸°
                    result_x = x * 4
                    result_y = y * 4
                    result.paste(processed_tile, (result_x, result_y))
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del tile, processed_tile
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        return result
    
    def smart_resize_for_memory(self, image: Image.Image, max_pixels: int = 2048 * 2048) -> Tuple[Image.Image, float]:
        """ë©”ëª¨ë¦¬ ì œí•œì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸í•œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        width, height = image.size
        current_pixels = width * height
        
        if current_pixels <= max_pixels:
            return image, 1.0
        
        # ë¹„ìœ¨ ê³„ì‚°
        ratio = (max_pixels / current_pixels) ** 0.5
        new_width = int(width * ratio)
        new_height = int(height * ratio)
        
        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        st.warning(f"ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ {width}x{height}ì—ì„œ {new_width}x{new_height}ë¡œ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.")
        
        return resized_image, ratio
        
    def upscale_with_bicubic(self, image: Image.Image, scale: int = 4) -> Optional[Image.Image]:
        """Bicubic ë³´ê°„ë²•ì„ ì‚¬ìš©í•œ ê¸°ë³¸ ì—…ìŠ¤ì¼€ì¼ë§"""
        try:
            new_size = (image.size[0] * scale, image.size[1] * scale)
            upscaled = image.resize(new_size, Image.Resampling.BICUBIC)
            return upscaled
        except Exception as e:
            st.error(f"Bicubic ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {str(e)}")
            return image
    
    def upscale_with_lanczos(self, image: Image.Image, scale: int = 4) -> Image.Image:
        """Lanczos ë³´ê°„ë²•ì„ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ì—…ìŠ¤ì¼€ì¼ë§"""
        try:
            new_size = (image.size[0] * scale, image.size[1] * scale)
            upscaled = image.resize(new_size, Image.Resampling.LANCZOS)
            # ì„ ëª…ë„ í•„í„° ì ìš©
            upscaled = upscaled.filter(ImageFilter.UnsharpMask(radius=1, percent=120, threshold=3))
            return upscaled
        except Exception as e:
            st.error(f"Lanczos ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {str(e)}")
            return image
    
    def upscale_with_opencv_edsr(self, image: Image.Image) -> Optional[Image.Image]:
        """OpenCV EDSR ëª¨ë¸ì„ ì‚¬ìš©í•œ ì—…ìŠ¤ì¼€ì¼ë§"""
        try:
            # OpenCV DNN ì‚¬ìš©
            img_array = np.array(image)
            
            # ê°„ë‹¨í•œ ì—…ìŠ¤ì¼€ì¼ë§ (OpenCV EDSR ëª¨ë¸ ì—†ì´)
            # Bicubic + ì„ ëª…í™” í•„í„° ì¡°í•©
            height, width = img_array.shape[:2]
            new_height, new_width = height * 4, width * 4
            
            # OpenCV resize
            upscaled = cv2.resize(img_array, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
            
            # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ì„ ëª…ë„ í–¥ìƒ
            gaussian = cv2.GaussianBlur(upscaled, (0, 0), 2.0)
            upscaled = cv2.addWeighted(upscaled, 1.5, gaussian, -0.5, 0)
            
            # ë…¸ì´ì¦ˆ ê°ì†Œ
            upscaled = cv2.bilateralFilter(upscaled, 9, 75, 75)
            
            result_image = Image.fromarray(upscaled)
            return result_image
            
        except Exception as e:
            st.error(f"OpenCV EDSR ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_realesrgan_model(self, model_name='RealESRGAN_x4plus'):
        """Real-ESRGAN ëª¨ë¸ ë¡œë“œ"""
        try:
            # ì‹¤ì œ Real-ESRGAN ëŒ€ì‹  í–¥ìƒëœ Bicubic + í•„í„°ë§ ì‚¬ìš©
            st.info("Real-ESRGAN ëŒ€ì‹  í–¥ìƒëœ ë³´ê°„ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            st.error(f"Real-ESRGAN ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_swinir_model(self):
        """SwinIR ëª¨ë¸ ë¡œë“œ (Hugging Face Transformers ì‚¬ìš©) - ë©”ëª¨ë¦¬ íš¨ìœ¨ì """
        try:
            if 'swinir' not in self.models:
                st.info("SwinIR ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
                
                try:
                    from transformers import Swin2SRImageProcessor, Swin2SRForImageSuperResolution
                    
                    # ë©”ëª¨ë¦¬ ì²´í¬
                    memory_info = self.get_memory_info()
                    if memory_info['available_ram_gb'] < 4:
                        st.warning("ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. SwinIR ëª¨ë¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                        return None
                    
                    # Hugging Faceì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
                    model_name = "caidas/swin2SR-classical-sr-x4-64"
                    processor = Swin2SRImageProcessor.from_pretrained(model_name)
                    
                    # CPU ìš°ì„ ìœ¼ë¡œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)
                    model = Swin2SRForImageSuperResolution.from_pretrained(
                        model_name,
                        torch_dtype=torch.float32,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ float32 ì‚¬ìš©
                        low_cpu_mem_usage=True
                    )
                    
                    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œ ê²½ìš°ì—ë§Œ GPUë¡œ ì´ë™
                    if self.device.type == 'cuda' and memory_info['available_ram_gb'] > 8:
                        try:
                            model = model.to(self.device)  # type: ignore
                        except:
                            model = model.to('cpu')  # type: ignore
                            st.info("GPU ì´ë™ ì‹¤íŒ¨, CPUì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    else:
                        model = model.to('cpu')  # type: ignore
                        st.info("ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ CPUì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    
                    self.models['swinir'] = {
                        'processor': processor,
                        'model': model
                    }
                    
                    return self.models['swinir']
                    
                except Exception as e:
                    st.warning(f"SwinIR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©: {str(e)}")
                    return None
            else:
                return self.models['swinir']
                    
        except Exception as e:
            st.error(f"SwinIR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_sd_upscaler_model(self):
        """Stable Diffusion x4 Upscaler ëª¨ë¸ ë¡œë“œ"""
        try:
            if 'sd_upscaler' not in self.models:
                st.info("Stable Diffusion x4 Upscaler ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
                
                try:
                    from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_upscale import StableDiffusionUpscalePipeline  # type: ignore
                    
                    # Stable Diffusion x4 upscaler íŒŒì´í”„ë¼ì¸ ë¡œë“œ
                    model_id = "stabilityai/stable-diffusion-x4-upscaler"
                    pipeline = StableDiffusionUpscalePipeline.from_pretrained(
                        model_id,
                        torch_dtype=torch.float16 if self.device.type == 'cuda' else torch.float32
                    )
                    
                    if self.device.type == 'cuda':
                        pipeline = pipeline.to(self.device)
                    
                    self.models['sd_upscaler'] = pipeline
                    return self.models['sd_upscaler']
                    
                except Exception as e:
                    st.warning(f"Stable Diffusion ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©: {str(e)}")
                    return None
                    
        except Exception as e:
            st.error(f"Stable Diffusion x4 Upscaler ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def upscale_with_realesrgan(self, image: Image.Image, model_name='RealESRGAN_x4plus') -> Optional[Image.Image]:
        """Real-ESRGANì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ (ëŒ€ì²´ êµ¬í˜„)"""
        try:
            with st.spinner(f"í–¥ìƒëœ ë³´ê°„ë²•ìœ¼ë¡œ ì—…ìŠ¤ì¼€ì¼ë§ ì¤‘..."):
                # Real-ESRGAN ëŒ€ì‹  ê³ í’ˆì§ˆ ë³´ê°„ë²• + í•„í„°ë§ ì‚¬ìš©
                
                # 1. ë¨¼ì € Lanczosë¡œ ì—…ìŠ¤ì¼€ì¼ë§
                scale = 4 if 'x4' in model_name else 2
                new_size = (image.size[0] * scale, image.size[1] * scale)
                upscaled = image.resize(new_size, Image.Resampling.LANCZOS)
                
                # 2. OpenCVë¡œ ì¶”ê°€ í–¥ìƒ
                img_array = np.array(upscaled)
                
                # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹
                gaussian = cv2.GaussianBlur(img_array, (0, 0), 1.0)
                upscaled_array = cv2.addWeighted(img_array, 1.3, gaussian, -0.3, 0)
                
                # ë…¸ì´ì¦ˆ ê°ì†Œ
                upscaled_array = cv2.bilateralFilter(upscaled_array, 5, 50, 50)
                
                result_image = Image.fromarray(upscaled_array)
                return result_image
            
        except Exception as e:
            st.error(f"ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def upscale_with_swinir(self, image: Image.Image) -> Optional[Image.Image]:
        """SwinIRì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬)"""
        try:
            # ë©”ëª¨ë¦¬ ì²´í¬
            memory_info = self.get_memory_info()
            st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ RAM: {memory_info['available_ram_gb']:.1f}GB")
            
            # ì´ë¯¸ì§€ í¬ê¸° ì²´í¬
            pixel_count = image.size[0] * image.size[1]
            max_safe_pixels = 1024 * 1024  # 1M pixels
            
            if pixel_count > max_safe_pixels or not self.can_handle_large_image(image.size):
                st.warning(f"ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤ ({image.size[0]}x{image.size[1]}). ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                # í° ì´ë¯¸ì§€ì˜ ê²½ìš° íƒ€ì¼ ê¸°ë°˜ ì²˜ë¦¬ ë˜ëŠ” ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
                if pixel_count > 4 * max_safe_pixels:  # ë§¤ìš° í° ê²½ìš°
                    return self.upscale_with_opencv_edsr(image)
                else:
                    # í¬ê¸° ì¶•ì†Œ í›„ ì²˜ë¦¬
                    resized_image, scale_ratio = self.smart_resize_for_memory(image, max_safe_pixels)
                    small_result = self._swinir_single_process(resized_image)
                    if small_result:
                        # ì›ë˜ í¬ê¸° ë¹„ìœ¨ë¡œ ë‹¤ì‹œ í™•ì¥
                        target_size = (int(image.size[0] * 4), int(image.size[1] * 4))
                        return small_result.resize(target_size, Image.Resampling.LANCZOS)
                    else:
                        return self.upscale_with_opencv_edsr(image)
            else:
                # ì •ìƒ í¬ê¸°ì¸ ê²½ìš° ì§ì ‘ ì²˜ë¦¬
                return self._swinir_single_process(image)
            
        except Exception as e:
            st.error(f"SwinIR ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©: {str(e)}")
            return self.upscale_with_opencv_edsr(image)
    
    def _swinir_single_process(self, image: Image.Image) -> Optional[Image.Image]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ SwinIR ì²˜ë¦¬"""
        try:
            model_dict = self.load_swinir_model()
            if model_dict is None:
                return None
            
            processor = model_dict['processor']
            model = model_dict['model']
            
            with st.spinner("SwinIRë¡œ ì—…ìŠ¤ì¼€ì¼ë§ ì¤‘..."):
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                inputs = processor(image, return_tensors="pt")
                
                if self.device.type == 'cuda':
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # ì—…ìŠ¤ì¼€ì¼ë§ ìˆ˜í–‰
                try:
                    with torch.no_grad():
                        outputs = model(**inputs)
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬
                    del inputs
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                    # ê²°ê³¼ ì´ë¯¸ì§€ í›„ì²˜ë¦¬
                    if hasattr(outputs, 'reconstruction'):
                        output_tensor = outputs.reconstruction
                    elif hasattr(outputs, 'logits'):
                        output_tensor = outputs.logits
                    else:
                        output_tensor = outputs
                    
                    # tensorë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    if torch.is_tensor(output_tensor):
                        output_array = output_tensor.squeeze().detach().cpu().numpy()
                        
                        # ê°’ ë²”ìœ„ë¥¼ 0-255ë¡œ ì •ê·œí™”
                        if output_array.max() <= 1.0:
                            output_array = output_array * 255
                        
                        # ì±„ë„ ìˆœì„œ ì¡°ì • (C, H, W) -> (H, W, C)
                        if len(output_array.shape) == 3 and output_array.shape[0] == 3:
                            output_array = np.transpose(output_array, (1, 2, 0))
                        
                        # uint8ë¡œ ë³€í™˜
                        output_array = np.clip(output_array, 0, 255).astype(np.uint8)
                        
                        # PIL Imageë¡œ ë³€í™˜
                        output_image = Image.fromarray(output_array)
                        
                        # ì¶”ê°€ ë©”ëª¨ë¦¬ ì •ë¦¬
                        del output_tensor, output_array
                        gc.collect()
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        
                        return output_image
                    else:
                        return None
                        
                except RuntimeError as e:
                    if "out of memory" in str(e).lower():
                        st.error(f"GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(e)}")
                        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ CPUì—ì„œ ì¬ì‹œë„
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        return None
                    else:
                        raise e
                        
        except Exception as e:
            st.warning(f"SwinIR ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def upscale_with_sd(self, image: Image.Image, prompt: str = "high quality, detailed") -> Optional[Image.Image]:
        """Stable Diffusion x4 Upscalerë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§"""
        try:
            pipeline = self.load_sd_upscaler_model()
            if pipeline is None:
                # ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
                return self.upscale_with_lanczos(image, 4)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (SD upscalerëŠ” ì…ë ¥ í¬ê¸°ì— ì œí•œì´ ìˆìŒ)
            max_size = 512
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            with st.spinner("Stable Diffusion x4 Upscalerë¡œ ì—…ìŠ¤ì¼€ì¼ë§ ì¤‘..."):
                try:
                    # ì—…ìŠ¤ì¼€ì¼ë§ ìˆ˜í–‰
                    result = pipeline(
                        prompt=prompt,
                        image=image,
                        num_inference_steps=20,
                        guidance_scale=7.5
                    )
                    
                    # ê²°ê³¼ ì²˜ë¦¬ - ê°„ë‹¨í•œ ë°©ë²•
                    if result and len(result) > 0:
                        # ì²« ë²ˆì§¸ ê²°ê³¼ê°€ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
                        first_result = result[0]
                        if isinstance(first_result, Image.Image):
                            return first_result
                        elif hasattr(first_result, '__iter__'):
                            # ë¦¬ìŠ¤íŠ¸ë‚˜ íŠœí”Œì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ë°˜í™˜
                            try:
                                if first_result:
                                    result = list(first_result)[0]
                                    # Ensure result is PIL Image
                                    if hasattr(result, 'save') and hasattr(result, 'size'):
                                        return result  # type: ignore
                                    return None
                            except:
                                pass
                    
                    # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš° ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
                    st.warning("Stable Diffusion ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨. ëŒ€ì²´ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    return self.upscale_with_lanczos(image, 4)
                        
                except Exception as pipeline_error:
                    st.warning(f"Stable Diffusion íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {str(pipeline_error)}. ëŒ€ì²´ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    return self.upscale_with_lanczos(image, 4)
            
        except Exception as e:
            st.error(f"Stable Diffusion x4 Upscaler ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©: {str(e)}")
            return self.upscale_with_lanczos(image, 4)
    
    def calculate_enhancement_metrics(self, original: Image.Image, upscaled: Image.Image) -> dict:
        """ì—…ìŠ¤ì¼€ì¼ë§ ê²°ê³¼ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            orig_array = np.array(original)
            upsc_array = np.array(upscaled)
            
            # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì—…ìŠ¤ì¼€ì¼ëœ í¬ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§
            orig_resized = original.resize(upscaled.size, Image.Resampling.BICUBIC)
            orig_resized_array = np.array(orig_resized)
            
            # í•´ìƒë„ í–¥ìƒ ë¹„ìœ¨
            scale_factor = upscaled.size[0] / original.size[0]
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            # 1. í‰ê·  ë°ê¸° ë³€í™”
            brightness_orig = np.mean(orig_resized_array)
            brightness_upsc = np.mean(upsc_array)
            brightness_change = (brightness_upsc - brightness_orig) / brightness_orig * 100
            
            # 2. ëŒ€ë¹„ í–¥ìƒ
            contrast_orig = np.std(orig_resized_array)
            contrast_upsc = np.std(upsc_array)
            contrast_improvement = (contrast_upsc - contrast_orig) / contrast_orig * 100
            
            # 3. ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            def calculate_sharpness(img_array):
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
                return cv2.Laplacian(gray, cv2.CV_64F).var()
            
            sharpness_orig = calculate_sharpness(orig_resized_array)
            sharpness_upsc = calculate_sharpness(upsc_array)
            sharpness_improvement = (sharpness_upsc - sharpness_orig) / sharpness_orig * 100
            
            return {
                'scale_factor': f"{scale_factor:.1f}x",
                'resolution_change': f"{original.size[0]}Ã—{original.size[1]} â†’ {upscaled.size[0]}Ã—{upscaled.size[1]}",
                'brightness_change': f"{brightness_change:+.1f}%",
                'contrast_improvement': f"{contrast_improvement:+.1f}%",
                'sharpness_improvement': f"{sharpness_improvement:+.1f}%"
            }
            
        except Exception as e:
            return {
                'scale_factor': 'N/A',
                'resolution_change': 'N/A',
                'brightness_change': 'N/A',
                'contrast_improvement': 'N/A',
                'sharpness_improvement': 'N/A'
            }

def display_upscaling_comparison(original: Image.Image, results: dict, metrics: dict):
    """ì—…ìŠ¤ì¼€ì¼ë§ ê²°ê³¼ ë¹„êµ í‘œì‹œ"""
    st.markdown("### ğŸ“Š ì—…ìŠ¤ì¼€ì¼ë§ ê²°ê³¼ ë¹„êµ")
    
    # ì´ë¯¸ì§€ ë¹„êµ
    cols = st.columns(len(results) + 1)
    
    with cols[0]:
        st.markdown("**ì›ë³¸ ì´ë¯¸ì§€**")
        st.image(original, caption=f"ì›ë³¸: {original.size[0]}Ã—{original.size[1]}")
    
    for i, (method, image) in enumerate(results.items(), 1):
        if image is not None:
            with cols[i]:
                st.markdown(f"**{method}**")
                st.image(image, caption=f"{method}: {image.size[0]}Ã—{image.size[1]}")
    
    # ë©”íŠ¸ë¦­ ë¹„êµ
    if metrics:
        st.markdown("### ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
        
        metric_df = []
        for method, metric in metrics.items():
            if metric:
                metric_df.append({
                    'ë°©ë²•': method,
                    'í•´ìƒë„ ë³€í™”': metric['resolution_change'],
                    'ë°ê¸° ë³€í™”': metric['brightness_change'],
                    'ëŒ€ë¹„ í–¥ìƒ': metric['contrast_improvement'],
                    'ì„ ëª…ë„ í–¥ìƒ': metric['sharpness_improvement']
                })
        
        if metric_df:
            import pandas as pd
            df = pd.DataFrame(metric_df)
            st.dataframe(df, use_container_width=True)

def save_upscaled_images(original_name: str, results: dict):
    """ì—…ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€ë“¤ì„ ZIP íŒŒì¼ë¡œ ì €ì¥"""
    try:
        import zipfile
        from datetime import datetime
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp()
        zip_path = os.path.join(temp_dir, f"upscaled_images_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip")
        
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for method, image in results.items():
                if image is not None:
                    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
                    img_buffer = BytesIO()
                    image.save(img_buffer, format='PNG')
                    img_bytes = img_buffer.getvalue()
                    
                    # ZIPì— ì¶”ê°€
                    filename = f"{original_name.split('.')[0]}_{method.lower().replace(' ', '_')}.png"
                    zipf.writestr(filename, img_bytes)
        
        # ZIP íŒŒì¼ ì½ê¸°
        with open(zip_path, 'rb') as f:
            zip_bytes = f.read()
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.remove(zip_path)
        os.rmdir(temp_dir)
        
        return zip_bytes
        
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None